{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import dask_image.ndfilters as dif\n",
    "import dask_ml.cluster\n",
    "import dask_ml.model_selection as dms\n",
    "from dask_ml.wrappers import Incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = \"D:\\\\CapstoneData\\\\labelled\\\\data\\\\real_training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(training_data_path)\n",
    "files = [file for file in files if file.endswith('.zarr') ]\n",
    "\n",
    "labels = [file for file in files if file.endswith(\"CGT.zarr\")]\n",
    "images = [file for file in files if file not in labels]\n",
    "\n",
    "images = sorted(images)\n",
    "labels = sorted(labels)\n",
    "\n",
    "X_y_files = []\n",
    "\n",
    "for i in images:\n",
    "    number = i.split(\"T\")[1].split(\"_\")[0]\n",
    "    number = int(number)\n",
    "    X_y_files.append([i, labels[number]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for files in X_y_files:\n",
    "    new_y = zarr.open(training_data_path + \"\\\\\" + files[1], mode='r')[\"volume\"][:]\n",
    "    y.append(new_y)\n",
    "\n",
    "    X_path = training_data_path + \"\\\\\" + files[0]\n",
    "    new_X = da.from_zarr(X_path, \"volume\")\n",
    "    try:\n",
    "        laplacian = da.from_zarr(X_path, \"laplacian\")\n",
    "    except:\n",
    "        laplacian = dif.gaussian_laplace(new_X, 2.5)\n",
    "        da.to_zarr(laplacian, X_path, \"laplacian\")\n",
    "\n",
    "    arrs = [laplacian, new_X]\n",
    "    arrs = [arr.ravel() for arr in arrs]\n",
    "    stacked = da.stack(arrs, -1)\n",
    "    X.append(stacked)\n",
    "\n",
    "y = da.from_array(np.array(y).flatten())\n",
    "X = da.concatenate(X)\n",
    "\n",
    "# Need to rechunk X for the train test split\n",
    "X = X.rechunk({1: X.shape[1]})\n",
    "\n",
    "# Make y match the X chunks\n",
    "y = y.rechunk(X.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data_path = \"D:\\\\CapstoneData\\\\labelled\\\\data\\\\training.zarr\"\n",
    "\n",
    "da.to_zarr(X, saved_data_path, \"X\")\n",
    "da.to_zarr(y, saved_data_path, \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortcut to just load the data from zarr after everything above has been done\n",
    "saved_data_path = \"D:\\\\CapstoneData\\\\labelled\\\\data\\\\training.zarr\"\n",
    "\n",
    "X = da.from_zarr(saved_data_path, \"X\")\n",
    "y = da.from_zarr(saved_data_path, \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, args=[], kwargs={}, train_size=0.0001, trials=5) -> list[int]:\n",
    "    scores = []\n",
    "    for i in range(trials):\n",
    "        print(f\"Run {i}\")\n",
    "        X_train, X_test, y_train, y_test = dms.train_test_split(X, y, train_size=train_size)\n",
    "        m = model(*args, **kwargs)\n",
    "        m = Incremental(m)\n",
    "        try:\n",
    "            m.fit(X_train, y_train, classes=[0,1])\n",
    "        except:\n",
    "            # Kmeans does not use classes\n",
    "            m.fit(X_train, y_train)\n",
    "        scores.append(m.score(X_test, y_test))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "Run 1\n",
      "Run 2\n",
      "Run 3\n",
      "Run 4\n",
      "[0.915117214888993, 0.9154836755237594, 0.9100087062903494, 0.9146144648068033, 0.8841088126278305]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_scores = test_model(SGDClassifier)\n",
    "print(sgd_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "Run 1\n",
      "Run 2\n",
      "Run 3\n",
      "Run 4\n",
      "[-942517419769856.0, -692646154600448.0, -699370194337792.0, -960529304649728.0, -710434164310016.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "kmeans_scores = test_model(MiniBatchKMeans, kwargs={\"n_clusters\": 2})\n",
    "print(kmeans_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
